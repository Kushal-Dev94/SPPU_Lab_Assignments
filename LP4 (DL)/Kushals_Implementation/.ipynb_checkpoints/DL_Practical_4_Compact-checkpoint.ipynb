{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a543112b-6c3c-4740-8357-668c9c4ad090",
   "metadata": {},
   "source": [
    "Assignment No: 04\n",
    "\n",
    "Aim: To implement Autoencoder for anomaly detection.\n",
    "\n",
    "Problem Statement:\n",
    "Use Autoencoder to implement anomaly detection. Build the model by using:\n",
    "a. Import required libraries\n",
    "b. Upload / access the dataset\n",
    "c. Encoder converts it into latent representation\n",
    "d. Decoder networks convert it back to the original input\n",
    "e. Compile the models with Optimizer, Loss, and Evaluation Metrics.\n",
    "Objectives:\n",
    "a) Apply Autoencoder deep learning architecture to determine anomalies in input dataset\n",
    "b) Evaluate Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a6718e-f378-4f9f-8d7d-3bc5f1189a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers, losses, metrics\n",
    "\n",
    "print(\"Imports complete!\")\n",
    "\n",
    "# b) Upload / access the dataset\n",
    "\n",
    "with np.load(r\"C:\\Users\\kusha\\Desktop\\mnist_dataset.npz\") as data:\n",
    "    x_train_all = data[\"X_train\"]\n",
    "    y_train_all = data[\"y_train\"]\n",
    "    x_test_all  = data[\"X_test\"]\n",
    "    y_test_all  = data[\"y_test\"]\n",
    "\n",
    "print(\n",
    "    f\"x_train_all:\\n\"\n",
    "    f\"  Data type: {x_train_all.dtype}\\n\"\n",
    "    f\"  Shape    : {x_train_all.shape}\\n\"\n",
    "    f\"  Pixel value range: {x_train_all.min()} to {x_train_all.max()}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"y_train_all:\\n\"\n",
    "    f\"  Data type: {y_train_all.dtype}\\n\"\n",
    "    f\"  Shape    : {y_train_all.shape}\\n\"\n",
    "    f\"  First 10 labels: {y_train_all[:10]}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"x_test_all:\\n\"\n",
    "    f\"  Data type: {x_test_all.dtype}\\n\"\n",
    "    f\"  Shape    : {x_test_all.shape}\\n\"\n",
    "    f\"  Pixel value range: {x_test_all.min()} to {x_test_all.max()}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"y_test_all:\\n\"\n",
    "    f\"  Data type: {y_test_all.dtype}\\n\"\n",
    "    f\"  Shape    : {y_test_all.shape}\\n\"\n",
    "    f\"  First 10 labels: {y_test_all[:10]}\\n\"\n",
    ")\n",
    "print(f\"First image sample of x_train_all (pixel values):\\n{x_train_all[0]}\\n\")\n",
    "\n",
    "# Normalize and reshape for CNN\n",
    "x_train_all = (x_train_all.astype(\"float32\") / 255.0)[..., None]\n",
    "x_test_all  = (x_test_all.astype(\"float32\")  / 255.0)[..., None]\n",
    "\n",
    "# Use digit '1' as normal class for training (anomaly detection)\n",
    "normal_class = 1\n",
    "x_train = x_train_all[y_train_all == normal_class]\n",
    "x_test  = x_test_all\n",
    "y_test  = y_test_all\n",
    "\n",
    "print(\n",
    "    f\"\\nAfter normalization and selection for anomaly detection:\\n\"\n",
    "    f\"Training on digit '{normal_class}' only.\\n\"\n",
    "    f\"x_train: {x_train.shape}, x_test: {x_test.shape}\\n\"\n",
    ")\n",
    "\n",
    "# c) Encoder network: converts input to latent representation\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "latent_dim = 16\n",
    "\n",
    "encoder_inputs = layers.Input(shape=input_shape)\n",
    "x = layers.Conv2D(32, 3, strides=2, padding='same', activation='relu')(encoder_inputs) # (14,14,32)\n",
    "x = layers.Conv2D(64, 3, strides=2, padding='same', activation='relu')(x)              # (7,7,64)\n",
    "x = layers.Flatten()(x)\n",
    "latent = layers.Dense(latent_dim, name=\"latent\")(x)\n",
    "encoder = Model(encoder_inputs, latent, name=\"encoder\")\n",
    "\n",
    "print(\"Encoder architecture:\")\n",
    "encoder.summary()\n",
    "\n",
    "# d) Decoder network: reconstructs input from latent\n",
    "\n",
    "latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7*7*64, activation='relu')(latent_inputs)\n",
    "x = layers.Reshape((7,7,64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)  # (14,14,64)\n",
    "x = layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu')(x)  # (28,28,32)\n",
    "decoded = layers.Conv2D(1, 3, padding='same', activation='sigmoid')(x)              # (28,28,1)\n",
    "decoder = Model(latent_inputs, decoded, name=\"decoder\")\n",
    "\n",
    "print(\"Decoder architecture:\")\n",
    "decoder.summary()\n",
    "\n",
    "# e) Compile the complete autoencoder\n",
    "\n",
    "autoencoder_inputs = layers.Input(shape=input_shape)\n",
    "encoded = encoder(autoencoder_inputs)\n",
    "reconstructed = decoder(encoded)\n",
    "autoencoder = Model(autoencoder_inputs, reconstructed, name=\"autoencoder\")\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.BinaryCrossentropy(),\n",
    "    metrics=[metrics.MeanSquaredError()]\n",
    ")\n",
    "\n",
    "print(\"Autoencoder architecture:\")\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the model (train only on normal class)\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    verbose=2\n",
    ")\n",
    "print(\"Training complete!\\n\")\n",
    "\n",
    "# Evaluate/analyze: Compute reconstruction error threshold for anomaly detection\n",
    "\n",
    "# Reconstruct training data for threshold\n",
    "recon_train = autoencoder.predict(x_train)\n",
    "train_mse = np.mean((recon_train - x_train) ** 2, axis=(1,2,3))\n",
    "\n",
    "# Use simple threshold: mean + 3*std of normal training errors\n",
    "threshold = train_mse.mean() + 3 * train_mse.std()\n",
    "print(f\"Anomaly threshold (mean + 3*std): {threshold:.6f}\")\n",
    "\n",
    "# Reconstruct test data\n",
    "recon_test = autoencoder.predict(x_test)\n",
    "test_mse = np.mean((recon_test - x_test) ** 2, axis=(1,2,3))\n",
    "anomaly_flags = test_mse > threshold\n",
    "\n",
    "print(\"Total test samples:\", len(x_test))\n",
    "print(\"Detected anomalies:\", np.sum(anomaly_flags))\n",
    "\n",
    "# Visualization: Show original and reconstruction, highlight anomalies vs. normal\n",
    "\n",
    "is_normal_test = (y_test == normal_class)\n",
    "n = 6\n",
    "plt.figure(figsize=(12, 5))\n",
    "example_idx = np.concatenate([\n",
    "    np.where(is_normal_test)[0][:n//2],\n",
    "    np.where(~is_normal_test)[0][:n - n//2]\n",
    "])\n",
    "\n",
    "for i, idx in enumerate(example_idx):\n",
    "    # original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[idx].reshape(28,28), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(f\"True:{y_test[idx]} Err:{test_mse[idx]:.4f}\")\n",
    "    plt.axis('off')\n",
    "    # reconstruction\n",
    "    ax = plt.subplot(2, n, n + i + 1)\n",
    "    plt.imshow(recon_test[idx].reshape(28,28), cmap='gray', vmin=0, vmax=1)\n",
    "    flag = \"ANOMALY\" if anomaly_flags[idx] else \"NORMAL\"\n",
    "    plt.title(flag)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"Original (top row) vs Reconstruction (bottom row)\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
